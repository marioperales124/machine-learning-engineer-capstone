{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just in case importing surprise does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transform_data.input_books import BooksReader\n",
    "from src.transform_data.input_interactions import InteractionsReader\n",
    "from src.transform_data.rating import Rating\n",
    "from src.transform_data.author_preparation import AuthorPreparation\n",
    "from src.transform_data.books_authors import BookAuthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection.search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL for books and interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = BooksReader().get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = InteractionsReader().get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'# books in books dataset {books_df.Name.nunique()}')\n",
    "print(f'# authors in books dataset {books_df.Authors.nunique()}')\n",
    "print(f'# authors in books dataset {books_df.Authors.nunique()}')\n",
    "\n",
    "print(f'# books in interactions dataset {interactions_df.item_des.nunique()}')\n",
    "print(f'# users in interactions dataset {interactions_df.user_id.nunique()}')\n",
    "print(f'Unique ratings in interactions dataset {interactions_df.ratings.unique()}')\n",
    "print(f'# ratings that are not zero {interactions_df[interactions_df.ratings!=0].count().iloc[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = interactions_df[interactions_df.ratings!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "interactions_df.ratings.hist(bins=50, figsize=(13, 8))\n",
    "plt.xlabel('Number of ratings', size=13)\n",
    "plt.ylabel('Counts', size=13)\n",
    "plt.xticks(size=11)\n",
    "plt.yticks(size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.groupby('item_des').count()['ratings'].hist(bins=30, figsize=(13, 8))\n",
    "plt.xlabel('Histogram of number of ratings for the items', size=13)\n",
    "plt.ylabel('Counts', size=13)\n",
    "plt.xticks(size=11)\n",
    "plt.yticks(size=11)\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a lot of books with only one or two ratings. In normal circumstances, I would filter these books. However, the little amount of data prevents me from discarding this and I am going to keep this data due to the amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.groupby('user_id').count()['ratings'].hist(bins=30, figsize=(13, 8))\n",
    "plt.xlabel('Histogram of number of ratings by user', size=13)\n",
    "plt.ylabel('Counts', size=13)\n",
    "plt.xticks(size=11)\n",
    "plt.yticks(size=11)\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the effect exists again. However, it seems not to be as sharp as the previous one, since we have only 4100 users and around 300K ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.groupby('item_des').mean()['ratings'].hist(bins=20, figsize=(13, 8))\n",
    "plt.xlabel('Average rating for items', size=13)\n",
    "plt.ylabel('Counts', size=13)\n",
    "plt.xticks(size=11)\n",
    "plt.yticks(size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df.groupby('user_id').mean()['ratings'].hist(bins=20, figsize=(13, 8))\n",
    "plt.xlabel('Average rating for users', size=13)\n",
    "plt.ylabel('Counts', size=13)\n",
    "plt.xticks(size=11)\n",
    "plt.yticks(size=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that most of the users really like what they read and rate. This could be a bias if people do not rate books that they do not like, but we cannot know this for sure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples for first approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example for Algorithm 1. Matrix Factorization\n",
    "\n",
    "A matrix factorization is a way of reducing a matrix into its constituent parts. It is an approach that can simplify more complex matrix operations that can be performed on the decomposed matrix rather than on the original matrix itself. More details in project document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surprise_alg_1 = Rating(interactions_df).get_surprise_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(n_factors=3, n_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = cross_validate(svd, dataset_surprise_alg_1, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example for Algorithm 2. Combined matrix with Matrix Factorization\n",
    "\n",
    "For this algorithm, We want to introduce bias for A adding the author information. The way to do this is in the project document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = (AuthorPreparation(alpha=0.2, col_author='Author', \n",
    "                            df_interactions=interactions_df, \n",
    "                            df_books=books_df.drop_duplicates())\n",
    "           .put_author_bias()\n",
    "          )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_surprise_alg_2 = Rating(df_join).get_surprise_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD(n_factors=n_factors, n_epochs=grid['n_epochs'][0], random_state=1)\n",
    "kf = KFold(n_splits=5, random_state=1)\n",
    "rmse_list = []\n",
    "for uad, uar in zip(kf.split(user_authors_dat), kf.split(user_authors_real)):\n",
    "    trainset, _ = uad\n",
    "    _, testset = uar\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    rmse_list.append(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model benchmark. Tuning parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm 1. Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'n_factors': [1,2,3,5,7,10], 'n_epochs': [15]}\n",
    "gs = GridSearchCV(SVD, grid, cv=5, n_jobs=-1)\n",
    "gs.fit(dataset_surprise_alg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,9))\n",
    "plt.plot([1,2,3,5,7,10],gs.cv_results['mean_test_rmse'])\n",
    "plt.title('RMSE mean for n_factors', size=14)\n",
    "plt.xlabel('# factors', size=12)\n",
    "plt.ylabel('RMSE', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm 2. Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "alphas_grid = np.linspace(0.25,1,4)\n",
    "print(alphas_grid)\n",
    "dict_gs = {}\n",
    "dict_best_params = {}\n",
    "for al in alphas_grid:\n",
    "    df_join = (AuthorPreparation(alpha=al, col_author='Author', \n",
    "                            df_interactions=interactions_df, \n",
    "                            df_books=books_df.drop_duplicates())\n",
    "           .put_author_bias()\n",
    "          )\n",
    "    dataset_surprise_alg_2 = Rating(df_join).get_surprise_dataset()\n",
    "    grid = {'n_factors': [1,2,3,5,7], 'n_epochs': [15]}\n",
    "    dict_gs[al] = {}\n",
    "    for n_factors in grid['n_factors']:\n",
    "        algo = SVD(n_factors=n_factors, n_epochs=grid['n_epochs'][0], random_state=1)\n",
    "        kf = KFold(n_splits=5, random_state=1)\n",
    "        rmse_list = []\n",
    "        for uad, uar in zip(kf.split(dataset_surprise_alg_2), kf.split(dataset_surprise_alg_1)):\n",
    "            trainset, _ = uad\n",
    "            _, testset = uar\n",
    "            algo.fit(trainset)\n",
    "            predictions = algo.test(testset)\n",
    "            rmse_list.append(accuracy.rmse(predictions))\n",
    "\n",
    "        \n",
    "        dict_gs[al][n_factors] = {'mean': np.mean(rmse_list), 'std': np.std(rmse_list)}\n",
    "        print(f'Done for # factors : {n_factors}')\n",
    "    print(f'Done for alpha : {al}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "dict_gs[0] = gs.cv_results\n",
    "dict_best_params[0] = gs.best_params['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best parameters results\n",
    "\n",
    "Build a table with alpha, n_factors y RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_gs[0.0] = {f:{'mean': dict_gs[0]['mean_test_rmse'][i], \n",
    "                   'std': dict_gs[0]['std_test_rmse'][i]}  \n",
    "                for i, f in enumerate([1, 2, 3, 5, 7])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_gs_m = {str(alpha)+'_'+str(n_f): dict_gs[alpha][n_f]['mean'] for n_f in [1, 2, 3, 5, 7] for alpha in [0,0.25,0.5,0.75,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_gs_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_df = pd.DataFrame.from_dict(dict_gs_m, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df = df_df.reset_index()\n",
    "df_df['alpha'] = df_df['index'].apply(lambda x: x.split('_')[0])\n",
    "df_df['n_factors'] = df_df['index'].apply(lambda x: x.split('_')[1])\n",
    "df_df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df.columns = ['RMSE', 'alpha', 'n_factors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_df.pivot(columns='alpha', index='n_factors', values='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,9))\n",
    "sns.scatterplot(data=df_df, hue='RMSE', x='alpha', y='n_factors', palette='Blues', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to a Sagemaker Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "import sagemaker\n",
    "bucket = 'recommendation-books-data'\n",
    "prefix = 'model'\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "# instantiate a pytorch estimator\n",
    "estimator = SKLearn(entry_point='train.py',\n",
    "                    source_dir='../src/sklearn_estimator/',\n",
    "                    role=role,\n",
    "                    py_version='py3',\n",
    "                    framework_version= '0.23-1',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c4.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 15,\n",
    "                        'alpha': 0.2,\n",
    "                        'n_factors': 3,\n",
    "                        'model-dir': '../model'\n",
    "                    }\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
